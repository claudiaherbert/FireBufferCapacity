{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown for Matching Fires from Multiple Years\n",
    "-------------\n",
    "C. Herbert, Date Started: 5.31.21\n",
    "\n",
    "*Notes: This Markdown uses Python 3 and geemap package. If you do not have these downloaded, along with the packages required, you will need to do this before being able to run this workbook. To uncomment code, remove the '#' symbol preceeding the line of code.*\n",
    "\n",
    "Prior to running this markdown you will need to be able to read the underlying Google Earth Engine (GEE) scripts to generate three continuous burn severity, Normalized Difference Moisture Index (NDMI), and Soil Adjusted Vegetation Index (SAVI). You can either run outputs yourself or connect to the public assets C. Herbert generated.\n",
    "\n",
    "**Overview**\n",
    "- Part I. (Python) Calls data from GEE to create CSVs of data sampling golf courses and non-golf courses that burned from 1984-2020\n",
    "- Part II. (Python) Reads in the CSVs created in Part I and creates some exploratory graphs\n",
    "- Part III. (R) Uses R package MatchIt to create propoensity scores + more graphs + match points\n",
    "- Part IV. (R) Uses linear regression to create t-test of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "# import rpy2\n",
    "ee.Initialize() # need to initialize the first time you use GEE\n",
    "import ee, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "# import seaborn as sns\n",
    "# from matplotlib import pyplot as plt # duplicated with the following line\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import style\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# from pymatch.Matcher import Matcher\n",
    "\n",
    "%matplotlib inline\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Define Boundaries and Create Sample Grid\n",
    "read in shapefiles of fire and landscape feature (golf) from GEE and define sample area\n",
    "### a. define the fire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imput the year of fire and the fire name\n",
    "year_num = 2003\n",
    "year = str(year_num)\n",
    "fire_name = 'SIMI FIRE' # 'SIMI FIRE'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. select golf course and fire for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded fire perimeter data on 5.6.2021, convert gdb to shp in ArcPro \n",
    "# direct download link: https://frap.fire.ca.gov/media/3nrpp42r/fire20_1.zip \n",
    "golf = ee.FeatureCollection('users/claudiaherbert/GolfCourse_FiresOverlapQuar_20211013')\n",
    "fires = ee.FeatureCollection('users/claudiaherbert/Firesp_20_1_update3').filter(ee.Filter.stringContains('YEAR_', year)).filter(ee.Filter.stringStartsWith('FIRE_NAME', fire_name))\n",
    "\n",
    "# select the golf course relevant to an input fire\n",
    "courses_year = golf.filter(ee.Filter.stringContains('FIRE_NAME', fire_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to select fires that overlap with burned treatment areas\n",
    "filt = ee.Filter.intersects('.geo', courses_year.geometry())\n",
    "fires_cntl = fires.filter(filt)\n",
    "fire_diff = fires_cntl.geometry().difference(courses_year.geometry())\n",
    "fire_poly = ee.FeatureCollection(fire_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the same because I have some datasets from the golf courses that seem to not be fully burned\n",
    "filt_t = ee.Filter.intersects('.geo', fire_poly.geometry())\n",
    "fires_treat = courses_year.filter(filt_t)\n",
    "fire_diff_t = fires_cntl.geometry().difference(fire_poly.geometry())\n",
    "fire_poly_treat = ee.FeatureCollection(fire_diff_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. create the sample grid\n",
    "Make all of the zones into different samples that will be one mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where I need to make a loop that goes through each of the fires for \n",
    "# one year and pulls the area size to sample on density\n",
    "courses_area = fire_poly_treat.map(lambda feature: ee.Feature(feature.set({'areaHa': feature.geometry().area().divide(100 * 100)})))\n",
    "fires_area = fire_poly.map(lambda feature: ee.Feature(feature.set({'areaHa': feature.geometry().area().divide(100 * 100)})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Golf Course Area: 160\n",
      "Total Fire Area: 43382\n"
     ]
    }
   ],
   "source": [
    "# Check that you are selecting the correct sized fire and golf course\n",
    "# a zero for either indicates that you may have had an error in your previous sections\n",
    "courses_samp = round(courses_area.aggregate_sum('areaHa').getInfo())\n",
    "fire_samp = round(fires_area.aggregate_sum('areaHa').getInfo())\n",
    "\n",
    "print('Total Golf Course Area:', courses_samp)\n",
    "print('Total Fire Area:', fire_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Golf Course\n",
    "features = ee.FeatureCollection([ee.Feature(fires_area.geometry(), {'group': 0}), ee.Feature(courses_area.geometry(), {'group': 1})])\n",
    "treatment = features.reduceToImage(['group'], ee.Reducer.mean()).select('mean').rename('group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be at 100 to make your sample point grid\n",
    "points = treatment.select('group').sampleRegions(collection= features, scale= 100, geometries= True, properties= ['group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment the following to check that you called the intended fire and golf course\n",
    "# Map = geemap.Map()\n",
    "# naip_url = 'https://services.nationalmap.gov/arcgis/services/USGSNAIPImagery/ImageServer/WMSServer?'\n",
    "# Map.add_wms_layer(url=naip_url, layers='0', name='NAIP Imagery', format='image/png', shown=True)\n",
    "# Map.addLayer(fires_area, {'color': 'd63000'}, 'difference') \n",
    "# Map.addLayer(fires, {'color': 'd63000'}, 'testing 2') \n",
    "# Map.addLayer(courses_year, {'color': 'd63000'}, 'testing') \n",
    "# Map.addLayer(courses_area, {'color': 'ffea00', 'width': 10, 'lineType': 'solid',}, 'Treatment Area')\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5d7b47aded491981f861f7b7f40776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40, -100], controls=(WidgetControl(options=['position'], widget=HBox(children=(ToggleButton(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "naip_url = 'https://services.nationalmap.gov/arcgis/services/USGSNAIPImagery/ImageServer/WMSServer?'\n",
    "Map.add_wms_layer(url=naip_url, layers='0', name='NAIP Imagery', format='image/png', shown=True)\n",
    "Map.addLayer(treatment, {'bands': ['group'], 'palette': ['#62ff42', ' #fb0aff'], 'min': 0.0, 'max': 2, 'opacity': 1.0}, 'Combined Sample Area')\n",
    "Map.addLayer(points, {'color': 'd63000'}, 'control points')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Create the fire-specific data\n",
    "Read in the layers from GEE needed for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precip: CHIRPS\n",
    "dataset = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\n",
    "\n",
    "# end date exclusive so range extends to following quarter\n",
    "# this calculates the total rainfall in mm/day during these three month periods\n",
    "precip_1 = dataset.filter(ee.Filter.date(year + '-01-01', year + '-04-01')).select('precipitation').sum()\n",
    "precip_2 = dataset.filter(ee.Filter.date(year + '-04-01', year + '-07-01')).select('precipitation').sum()\n",
    "precip_3 = dataset.filter(ee.Filter.date(year + '-07-01', year + '-10-01')).select('precipitation').sum()\n",
    "precip_4 = dataset.filter(ee.Filter.date(year + '-10-01', year + '-12-31')).select('precipitation').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude + longitude\n",
    "latitude = ee.Image.pixelLonLat().select('latitude')\n",
    "longitude = ee.Image.pixelLonLat().select('longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SIMIFIRE']\n"
     ]
    }
   ],
   "source": [
    "# Creating a unique identifer for each fire\n",
    "fires_info = fires_cntl.getInfo()\n",
    "\n",
    "ids = []\n",
    "\n",
    "for i in range (0,len(fires_info['features'])): \n",
    "    fire_dict = fires_info['features'][i]\n",
    "    fid = fire_dict['properties']['FIRE_NAME']  #['GIS_ACRES']\n",
    "    s_fid = str(fid)\n",
    "    nospace = s_fid.replace(\" \", \"\")\n",
    "    ids.append(nospace)\n",
    "    \n",
    "uid = np.unique(ids)\n",
    "print(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_id = fires_cntl.map(lambda feature: ee.Feature(feature.set({'FireId': ee.Number.parse(feature.get('id'))})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following fire severity data should be public if you are running one of the fires in our paper. If you are running a different fire, you will need to produce these outputs by going to our GEE script. Chaneg path as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with rdnbr_w_offset\n",
      "Finished with dnbr_w_offset\n",
      "Finished with rdnbr_w_offset\n"
     ]
    }
   ],
   "source": [
    "# Reading in the continuous data\n",
    "\n",
    "# create an empty list for us to add names\n",
    "rdnbr_paths = []\n",
    "# creating path names for rdnbr\n",
    "for i in range(0,len(uid)):   \n",
    "    path = ee.Image('users/claudiaherbert/InitialBurnSev_v2/' + str(uid[i]) + '_rdnbr_w_offset_' + year)\n",
    "    rdnbr_paths.append(path)\n",
    "\n",
    "rdnbr_w_offset = ee.ImageCollection(rdnbr_paths).max()\n",
    "print(\"Finished with rdnbr_w_offset\")\n",
    "\n",
    "# create an empty list for us to add names\n",
    "dnbr_paths = []\n",
    "# creating path names for dnbr\n",
    "for i in range(0,len(uid)):   \n",
    "    path = ee.Image('users/claudiaherbert/InitialBurnSev_v2/' + str(uid[i]) + '_dnbr_w_offset_' + year)\n",
    "    dnbr_paths.append(path)\n",
    "    \n",
    "dnbr_w_offset = ee.ImageCollection(dnbr_paths).max()\n",
    "print(\"Finished with dnbr_w_offset\")\n",
    "    \n",
    "# create an empty list for us to add names\n",
    "rbr_paths = []\n",
    "# creating path names for rbr\n",
    "for i in range(0,len(uid)):   \n",
    "    path = ee.Image('users/claudiaherbert/InitialBurnSev_v2/' + str(uid[i]) + '_rbr_w_offset_' + year)\n",
    "    rbr_paths.append(path)\n",
    "\n",
    "rbr_w_offset = ee.ImageCollection(rbr_paths).max()\n",
    "print(\"Finished with rdnbr_w_offset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with NDMI paths\n",
      "Finished with NDMI paths\n",
      "Finished with NDMI paths\n"
     ]
    }
   ],
   "source": [
    "# Reading in the veg NDMI data\n",
    "\n",
    "ndmi_1_paths = []\n",
    "# creating path names for ndmi\n",
    "for i in range(0,len(uid)):   \n",
    "    path = ee.Image('users/claudiaherbert/NDMI_v2/' + str(uid[i]) + '_NDMI_1_' + year)\n",
    "    ndmi_1_paths.append(path)\n",
    "\n",
    "ndmi_1 = ee.ImageCollection(ndmi_1_paths).max()\n",
    "print(\"Finished with NDMI paths\")\n",
    "\n",
    "# create an empty list for us to add names\n",
    "# users/claudiaherbert/NDMI/TAYLOR_NDMI_3_1998\n",
    "ndmi_3_paths = []\n",
    "# creating path names for ndmi\n",
    "for i in range(0,len(uid)):   \n",
    "    path = ee.Image('users/claudiaherbert/NDMI_v2/' + str(uid[i]) + '_NDMI_3_' + year)\n",
    "    ndmi_3_paths.append(path)\n",
    "\n",
    "ndmi_3 = ee.ImageCollection(ndmi_3_paths).max()\n",
    "print(\"Finished with NDMI paths\")\n",
    "\n",
    "ndmi_6_paths = []\n",
    "# creating path names for ndmi\n",
    "for i in range(0,len(uid)):   \n",
    "    path = ee.Image('users/claudiaherbert/NDMI_v2/' + str(uid[i]) + '_NDMI_6_' + year)\n",
    "    ndmi_6_paths.append(path)\n",
    "\n",
    "ndmi_6 = ee.ImageCollection(ndmi_6_paths).max()\n",
    "print(\"Finished with NDMI paths\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with SAVI paths\n"
     ]
    }
   ],
   "source": [
    "savi_paths = []\n",
    "# creating path names for savi\n",
    "for i in range(0,len(uid)):   \n",
    "    path = ee.Image('users/claudiaherbert/SAVI_v2/' + str(uid[i]) + '_SAVI_' + year)\n",
    "    savi_paths.append(path)\n",
    "\n",
    "savi = ee.ImageCollection(savi_paths).max()\n",
    "print(\"Finished with SAVI paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting a fire ID to use to keep analysis inter-fire\n",
    "# # fires_name = ee.FeatureCollection('users/claudiaherbert/FRAP_1kmGC_Names_2').filter(ee.Filter.eq('Year', year_num))\n",
    "\n",
    "def getCentroid(feature): \n",
    "    keepProperties = ['GIS_ACRES']\n",
    "    centroid = feature.geometry()\n",
    "    return ee.Feature(centroid).copyProperties(feature, keepProperties);\n",
    "\n",
    "centroids = fires_cntl.map(getCentroid)\n",
    "\n",
    "landAreaImg = centroids.filter(ee.Filter.notNull(['GIS_ACRES'])).reduceToImage(\n",
    "    properties = ['GIS_ACRES'],\n",
    "    reducer = ee.Reducer.first()).rename('GIS_ACRES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SRTM\n",
    "srtm = ee.Image('USGS/SRTMGL1_003')\n",
    "\n",
    "# Calculate elevation \n",
    "elevation = srtm.select('elevation')\n",
    "slope = ee.Terrain.slope(elevation)\n",
    "aspect = ee.Terrain.aspect(elevation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NLCD 2001\n"
     ]
    }
   ],
   "source": [
    "# Landcover pre-fire\n",
    "landcoverd_ds = ee.ImageCollection('USGS/NLCD_RELEASES/2016_REL')\n",
    "\n",
    "# NLCD Epochs 1992, 2001, 2004, 2006, 2008, 2011, 2013 and 2016\n",
    "# not using 1992 because there were different methods to determine landcover\n",
    "# I choose to use the epoch prior to the fire (where available) to get match on landcover pre-fire\n",
    "\n",
    "if year_num >= 2016: \n",
    "    # NLCD 2016\n",
    "    nlcd2016 = landcoverd_ds.filter(ee.Filter.eq('system:index', '2016')).first()\n",
    "    landcover = nlcd2016.select('landcover')\n",
    "    print(\"Using NLCD 2016\")\n",
    "elif year_num >= 2013: # or year_num < 2016:\n",
    "    # NLCD 2013\n",
    "    nlcd2013 = landcoverd_ds.filter(ee.Filter.eq('system:index', '2013')).first()\n",
    "    landcover = nlcd2013.select('landcover')\n",
    "    print(\"Using NLCD 2013\")\n",
    "elif year_num >= 2011: # or year_num < 2013:\n",
    "    # NLCD 2011\n",
    "    nlcd2011 = landcoverd_ds.filter(ee.Filter.eq('system:index', '2011')).first()\n",
    "    landcover = nlcd2011.select('landcover')\n",
    "    print(\"Using NLCD 2011\")\n",
    "elif year_num >= 2008: # or year_num < 2011:\n",
    "    # NLCD 2008\n",
    "    nlcd2008 = landcoverd_ds.filter(ee.Filter.eq('system:index', '2008')).first()\n",
    "    landcover = nlcd2008.select('landcover')\n",
    "    print(\"Using NLCD 2008\")    \n",
    "elif year_num >= 2006: # or year_num < 2008: \n",
    "    # NLCD 2006\n",
    "    nlcd2006 = landcoverd_ds.filter(ee.Filter.eq('system:index', '2006')).first()\n",
    "    landcover = nlcd2006.select('landcover')\n",
    "    print(\"Using NLCD 2006\")\n",
    "elif year_num >= 2004: # or year_num < 2006:\n",
    "    # NLCD 2004\n",
    "    nlcd2004 = landcoverd_ds.filter(ee.Filter.eq('system:index', '2004')).first()\n",
    "    landcover = nlcd2004.select('landcover')\n",
    "    print(\"Using NLCD 2004\")\n",
    "else:     \n",
    "    # NLCD 2001\n",
    "    nlcd2001 = landcoverd_ds.filter(ee.Filter.eq('system:index', '2001')).first()\n",
    "    landcover = nlcd2001.select('landcover')\n",
    "    print(\"Using NLCD 2001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Decennial 2000\n"
     ]
    }
   ],
   "source": [
    "# Census\n",
    "# Combination of ACS and Decennial Census accessed via 'tidycensus' package in R\n",
    "\n",
    "if year_num >= 2014: \n",
    "    # ACS 2014-2018\n",
    "    acs_2018 = ee.FeatureCollection('users/claudiaherbert/ca_18_20220106_v01').select('estimate')\n",
    "    income = acs_2018.reduceToImage(['estimate'], ee.Reducer.mean()).select('mean').rename('income')\n",
    "    print(\"Using ACS 2014 - 2018\")\n",
    "elif year_num >= 2010: # or year_num < 2016:\n",
    "    # ACS 2011 - 2013\n",
    "    acs_2013 = ee.FeatureCollection('users/claudiaherbert/ca_13_20220106_v01').select('estimate')\n",
    "    income = acs_2013.reduceToImage(['estimate'], ee.Reducer.mean()).select('mean').rename('income')\n",
    "    print(\"Using ACS 2011 - 2013\")\n",
    "elif year_num >= 2005: # or year_num < 2013:\n",
    "    # ACS 2005 - 2009\n",
    "    acs_2009 = ee.FeatureCollection('users/claudiaherbert/ca_09_20220106_v01').select('estimate')\n",
    "    income = acs_2009.reduceToImage(['estimate'], ee.Reducer.mean()).select('mean').rename('income')\n",
    "    print(\"Using ACS 2005 - 2009\")\n",
    "else:     \n",
    "    # Decennial 2000\n",
    "    acs_2000 = ee.FeatureCollection('users/claudiaherbert/ca_00_20220106_v01').select('value')\n",
    "    income = acs_2000.reduceToImage(['value'], ee.Reducer.mean()).select('mean').rename('income')\n",
    "    print(\"Using Decennial 2000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MTBS may not be available for your fire--check availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtbs_one = ee.Image('users/claudiaherbert/MTBS/mtbs_CA_' + year).select('b1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a raster stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a combined image with all relevant stats\n",
    "# dropped the following to test group\n",
    "\n",
    "combined_img = elevation.addBands(slope).addBands(aspect).addBands(landcover) \\\n",
    "            .addBands(precip_1).addBands(precip_2).addBands(precip_3).addBands(precip_4) \\\n",
    "            .addBands(latitude).addBands(longitude).addBands(landAreaImg).addBands(dnbr_w_offset) \\\n",
    "            .addBands(rbr_w_offset).addBands(rdnbr_w_offset).addBands(ndmi_3).addBands(ndmi_6) \\\n",
    "            .addBands(savi).addBands(treatment).addBands(income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f798c354244df28ecaf9f8a3648acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40, -100], controls=(WidgetControl(options=['position'], widget=HBox(children=(ToggleButton(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "Map.addLayer(combined_img, {'color': 'fd0808e2'}, 'Images')\n",
    "Map.addLayer(points, {'color': 'd63000'}, 'control points')\n",
    "# Map.addLayer(mtbs_one, {}, 'mtbs') # determine whether MTBS is available for this fire\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Extract points using geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/tables/8eebc24b348a478922a28b6a6f4ef395-5f2dafa9b7c3d88579a760ffdf19a948:getFeatures\n",
      "Please wait ...\n",
      "Data downloaded to C:\\Users\\claud\\Downloads\\grid_point_100m_SIMI FIRE_2003.csv\n"
     ]
    }
   ],
   "source": [
    " # Change this to a local path you want data downloaded\n",
    "work_dir = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "out_csv = os.path.join(work_dir, 'grid_point_100m_' + fire_name + \"_\"+ year + '.csv')\n",
    "geemap.extract_values_to_points(points, combined_img, out_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Read in CSVs and produce a single output\n",
    "After you have run the above workflow for all of the fires, you can combine the CSV outputs to be a single CSV that we will pass the the R Markdown for PSM and regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "list_files = glob.glob(\" << insert the path to where you downloaded your files >> /*.csv\")\n",
    "print(glob.glob(\"<< insert the path to where you downloaded your files >>/*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for x in range(0,len(list_files)):\n",
    "    df_1 = pd.read_csv(list_files[x])\n",
    "    year = int(list_files[x][-8:-4]) # will need to change this index if you change where the file names\n",
    "    df_1[\"year\"] = year\n",
    "    df = df.append(df_1, ignore_index = False)\n",
    "print(\"Finished with reading in CSVs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('<< insert the path to where you downloaded your files >> /GolfCourseSamplesMatching_CH_20220107_v01.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional, check the df\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
